{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main issue behind *single layer perceptron* was its inability to deal with data separation that is **not** linearly separable.\n",
    "Indeed, the famous **XOR**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![XOR Problem illustrated](img/xor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how long you will think about, there no straight line that would follow this property: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\text{Given a,b} \\in \\mathbb{R}^{*} \\text{and c} \\in \\mathbb{R}, \\text{we have the following equation: } $$\n",
       "$$ ax + by + c = 0$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$ \\text{Given a,b} \\in \\mathbb{R}^{*} \\text{and c} \\in \\mathbb{R}, \\text{we have the following equation: } $$\n",
    "$$ ax + by + c = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition\n",
    "\n",
    "For this exact problem of xor, one intuition we would have would be to use not one but **two** equations to linearly separate the given data, just like this.\n",
    "\n",
    "| ![XOR First Separation](img/xor_sol1.png) | ![XOR Second Separation](img/xor_sol2.png)  |\n",
    "|---|---|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we would have to combine the two to obtain such a result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![XOR First Separation](img/splitted_xor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> But then, how on earth would we do that, would we combine two Perceptrons ?\n",
    "\n",
    "Well, actually, the answer to this is not that far away, we would just have to add a new layer to our single layer perceptron : this layer is called a **hidden layer**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network would now go from this perceptron, to this multilayer perceptron (MLP):\n",
    "\n",
    "![scheme](https://cdn-images-1.medium.com/max/800/1*CJEBy3GCaGQKNx7PEy-w5w.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://towardsdatascience.com/multi-layer-neural-networks-with-sigmoid-function-deep-learning-for-rookies-2-bf464f09eb7f): Nahua Kang, Medium.com, *Multi-Layer Neural Networks with Sigmoid Functionâ€” Deep Learning for Rookies (2)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Implementation\n",
    "\n",
    "So now, we have to implement it with Keras. So first, let's deal with all the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.initializers as KI\n",
    "import keras.engine as KE\n",
    "import keras.models as KM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we setup our hyperparameters, as followed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10 #define the number of classes to be that of 10 classes\n",
    "\n",
    "NUM_OF_EPOCHS = 10 #define the number of epochs to be that of 10 epochs\n",
    "\n",
    "BATCH_SIZE = 32 #set the batch size at 32 inputs\n",
    "\n",
    "DEFAULT_INPUT_SHAPE = 1024 #define the input shape as a 1024 vector\n",
    "\n",
    "VALIDATION_DATA = 0.2 #define the split ratio between the training set (80%) and the validation set(20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get to business and start implementing our MLP Model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_input_shape = DEFAULT_INPUT_SHAPE\n",
    "default_num_classes = NUM_CLASSES\n",
    "\n",
    "model = KM.Sequential()\n",
    "\n",
    "# Model type definition\n",
    "fc1 = KL.Dense(32, input_shape=(default_input_shape,), activation='relu')\n",
    "dp2 = KL.Dropout(0.25)\n",
    "fc3 = KL.Dense(16, activation='relu')\n",
    "dp4 = KL.Dropout(rate=0.5)\n",
    "# Last layer has to have a softmax activation function\n",
    "fc5 = KL.Dense(default_num_classes,activation='softmax')\n",
    "\n",
    "model.add(fc1)\n",
    "model.add(dp2)\n",
    "model.add(fc3)\n",
    "model.add(dp4)\n",
    "model.add(fc5)\n",
    "\n",
    "# Compiling of the model\n",
    "model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
